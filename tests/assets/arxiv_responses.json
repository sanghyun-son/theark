{
  "1706.03762": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <entry>\n    <id>http://arxiv.org/abs/1706.03762</id>\n    <updated>2017-12-06T00:37:27Z</updated>\n    <published>2017-06-12T17:57:58Z</published>\n    <title>Attention Is All You Need</title>\n    <summary>The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and\nconvolutions entirely.</summary>\n    <author>\n      <name>Ashish Vaswani</name>\n    </author>\n    <author>\n      <name>Noam Shazeer</name>\n    </author>\n    <author>\n      <name>Niki Parmar</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/1706.03762\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1706.03762\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>",
  "9999.99999": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\n</feed>",
  "default": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <entry>\n    <id>http://arxiv.org/abs/1409.0575</id>\n    <updated>2014-09-01T22:29:38Z</updated>\n    <published>2014-09-01T22:29:38Z</published>\n    <title>ImageNet Large Scale Visual Recognition Challenge</title>\n    <summary>The ImageNet Large Scale Visual Recognition Challenge is a benchmark in\nobject category classification and detection on hundreds of object categories\nand millions of images. The challenge has been run annually from 2010 to\npresent, attracting participation from more than fifty institutions.\n  This paper describes the creation of this benchmark dataset and the advances\nin object recognition that have been possible as a result. We discuss the\nchallenges of collecting large-scale ground truth annotation, highlight key\nbreakthroughs in categorical object recognition, provide a detailed analysis of\nthe current state of the field of large-scale image classification and object\ndetection, and compare the state-of-the-art computer vision accuracy with human\naccuracy. We conclude with lessons learned in the five years of the challenge,\nand propose future directions and improvements.</summary>\n    <author>\n      <name>Olga Russakovsky</name>\n    </author>\n    <author>\n      <name>Jia Deng</name>\n    </author>\n    <author>\n      <name>Hao Su</name>\n    </author>\n    <author>\n      <name>Jonathan Krause</name>\n    </author>\n    <author>\n      <name>Sanjeev Satheesh</name>\n    </author>\n    <author>\n      <name>Sean Ma</name>\n    </author>\n    <author>\n      <name>Zhiheng Huang</name>\n    </author>\n    <author>\n      <name>Andrej Karpathy</name>\n    </author>\n    <author>\n      <name>Aditya Khosla</name>\n    </author>\n    <author>\n      <name>Michael Bernstein</name>\n    </author>\n    <author>\n      <name>Alexander C. Berg</name>\n    </author>\n    <author>\n      <name>Li Fei-Fei</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/1409.0575\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1409.0575\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"I.4.8; I.5.2\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>"
}
